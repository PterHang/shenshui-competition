{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# import lightgbm as lgb\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "# from lightgbm import LGBMClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('training_dataset/hourly_dataset.csv')\n",
    "train['time'] = pd.to_datetime(train['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 = train[(train['time']>='2022-01-01 01:00:00')&(train['time']<'2022-05-01 01:00:00')].reset_index(drop=True)\n",
    "# test1 = train[train['train or test']=='test1'].reset_index(drop=True)\n",
    "\n",
    "train2 = train[(train['time']>='2022-05-08 01:00:00')&(train['time']<'2022-06-01 01:00:00')].reset_index(drop=True)\n",
    "# test2 = train[train['train or test']=='test2'].reset_index(drop=True)\n",
    "\n",
    "train3 = train[(train['time']>='2022-06-08 01:00:00')&(train['time']<'2022-07-21 01:00:00')].reset_index(drop=True)\n",
    "# test3 = train[train['train or test']=='test3'].reset_index(drop=True)\n",
    "\n",
    "train4 = train[(train['time']>='2022-07-28 01:00:00')&(train['time']<'2022-08-21 01:00:00')].reset_index(drop=True)\n",
    "# test4 = train[train['train or test']=='test4'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.022728681564331055,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 4,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "748f6a958dad49c0bf734b6e3dbd7464",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.017000675201416016,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 4,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74c8802b2e0f481ab27c7f211922f198",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## 将小于零的值替换为空值\n",
    "for df in tqdm([train1,train2,train3,train4]):\n",
    "    for i in range(1,21):\n",
    "        df.loc[df[f'flow_{i}']<0,f'flow_{i}'] = np.nan\n",
    "        \n",
    "        \n",
    "## 将异常值替换为空值\n",
    "for df in tqdm([train1,train2,train3,train4]):\n",
    "    for i in range(1,21):\n",
    "        df[f'flow_{i}_shift'] = df[f'flow_{i}'].shift(-1)\n",
    "        for index,row in df.iterrows():\n",
    "            if index != df.shape[0]-1:\n",
    "                if pd.isna(row[f'flow_{i}_shift']) and pd.notna(row[f'flow_{i}']):\n",
    "                    df.loc[index,f'flow_{i}'] = np.nan\n",
    "        del df[f'flow_{i}_shift'];gc.collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.015004634857177734,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 2880,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec56f6a4629648a5af90c51cb21c59ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2880 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.012689828872680664,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 576,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ded1a8cb973c4aa0a40dd0fee48828bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/576 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.012999534606933594,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1032,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4180dd551b5d4a6b9f93e71597ace6c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1032 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.013000011444091797,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 576,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caec6f9646d54099930322d75420ae1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/576 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(1,5):\n",
    "    locals()[f'train{i}'] = locals()[f'train{i}'].set_index('time')\n",
    "    \n",
    "for df in [train1,train2,train3,train4]:\n",
    "    for date in tqdm(df.index):\n",
    "        for col in range(20):\n",
    "            period1 = pd.Timedelta(hours = 24)\n",
    "            if pd.isna(df.loc[date][col]): #判断是否为空值\n",
    "                if date - period1 in df.index: #如果该索引存在 （考虑到一下flow一开始就存在空值）\n",
    "                    period2 = date - period1\n",
    "                    while pd.isna(df.loc[period2][col]):\n",
    "                        period2 = period2 - period1\n",
    "                    df.loc[date, f'flow_{col+1}'] = df.loc[period2, f'flow_{col+1}']\n",
    "\n",
    "                else: #对于flow一开始就存在缺失值的，用后一天的值进行填充\n",
    "                    period2 = date + pd.Timedelta(hours = 24)\n",
    "                    while pd.isna(df.loc[period2][col]):\n",
    "                        period2 = period2 + period1\n",
    "                    df.loc[date, f'flow_{col+1}'] = df.loc[period2, f'flow_{col+1}']\n",
    "\n",
    "                \n",
    "for i in range(1,5):\n",
    "    locals()[f'train{i}'] = locals()[f'train{i}'].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\peterhuangzi\\AppData\\Local\\Temp\\ipykernel_20556\\710459956.py:24: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version.  Use .loc with labels or .iloc with positions instead.\n",
      "  sub.loc[(sub['time']>='2022-05-01 01:00:00')&(sub['time']<'2022-05-02 01:00:00'),1:] = sub1\n",
      "C:\\Users\\peterhuangzi\\AppData\\Local\\Temp\\ipykernel_20556\\710459956.py:39: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version.  Use .loc with labels or .iloc with positions instead.\n",
      "  sub.loc[(sub['time']>='2022-06-01 01:00:00')&(sub['time']<'2022-06-02 01:00:00'),1:] = sub2\n",
      "C:\\Users\\peterhuangzi\\AppData\\Local\\Temp\\ipykernel_20556\\710459956.py:53: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version.  Use .loc with labels or .iloc with positions instead.\n",
      "  sub.loc[(sub['time']>='2022-07-21 01:00:00')&(sub['time']<'2022-07-22 01:00:00'),1:] = sub3\n",
      "C:\\Users\\peterhuangzi\\AppData\\Local\\Temp\\ipykernel_20556\\710459956.py:67: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version.  Use .loc with labels or .iloc with positions instead.\n",
      "  sub.loc[(sub['time']>='2022-08-21 01:00:00')&(sub['time']<'2022-08-22 01:00:00'),1:] = sub4\n"
     ]
    }
   ],
   "source": [
    "sub = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "# sub1 = (train1.iloc[-24*7*1:,1:-1].values + train1.iloc[-24*7*2:-24*7*1,1:-1].values + \\\n",
    "#         train1.iloc[-24*7*3:-24*7*2,1:-1].values + train1.iloc[-24*7*4:-24*7*3,1:-1].values)/4\n",
    "# sub.loc[(sub['time']>='2022-05-01 01:00:00')&(sub['time']<'2022-05-08 01:00:00'),1:] = sub1\n",
    "\n",
    "\n",
    "# sub1 = (train2.iloc[-24*7*1:,1:-1].values + train2.iloc[-24*7*2:-24*7*1,1:-1].values + \\\n",
    "#         train2.iloc[-24*7*3:-24*7*2,1:-1].values)/3\n",
    "# sub.loc[(sub['time']>='2022-06-01 01:00:00')&(sub['time']<'2022-06-08 01:00:00'),1:] = sub1\n",
    "\n",
    "\n",
    "# sub1 = (train3.iloc[-24*7*1:,1:-1].values + train3.iloc[-24*7*2:-24*7*1,1:-1].values + \\\n",
    "#         train3.iloc[-24*7*3:-24*7*2,1:-1].values + train3.iloc[-24*7*4:-24*7*3,1:-1].values)/4\n",
    "# sub.loc[(sub['time']>='2022-07-21 01:00:00')&(sub['time']<'2022-07-28 01:00:00'),1:] = sub1\n",
    "\n",
    "\n",
    "# sub1 = (train4.iloc[-24*7*1:,1:-1].values + train4.iloc[-24*7*2:-24*7*1,1:-1].values + \\\n",
    "#         train4.iloc[-24*7*3:-24*7*2,1:-1].values)/3\n",
    "# sub.loc[(sub['time']>='2022-08-21 01:00:00')&(sub['time']<'2022-08-28 01:00:00'),1:] = sub1\n",
    "sub1 = ((train1.iloc[-24*7*1:-24*6,1:-1].values + train1.iloc[-24*7*2:-24*7*1-24*6,1:-1].values + \\\n",
    "         train1.iloc[-24*7*3:-24*7*2-24*6,1:-1].values + train1.iloc[-24*7*4:-24*7*3-24*6,1:-1].values)/4)\\\n",
    "             * 0.2 + train1.iloc[-24*1:,1:-1].values * 0.8\n",
    "sub.loc[(sub['time']>='2022-05-01 01:00:00')&(sub['time']<'2022-05-02 01:00:00'),1:] = sub1\n",
    "for i in range(2, 8):\n",
    "    if i == 7 :\n",
    "        sub.iloc[24*(i-1)*1:24*(i),1:] = ((train1.iloc[-24*1:,1:-1].values + train1.iloc[-24*7*1-24*1:-24*7*1,1:-1].values +\\\n",
    "            + train1.iloc[-24*7*2-24*1:-24*7*2,1:-1].values + train1.iloc[-24*7*3-24*1:-24*7*3,1:-1].values)/4)\\\n",
    "                 * 0.4 + sub.iloc[24*(i-2)*1:24*(i-1),1:].values * 0.6\n",
    "    else:\n",
    "        sub1 = ((train1.iloc[-24*(8-i)*1:-24*(7-i),1:-1].values + train1.iloc[-24*7*1-24*(8-i)*1:-24*7*1-24*(7-i),1:-1].values +\\\n",
    "            train1.iloc[-24*7*2-24*(8-i)*1:-24*7*2-24*(7-i),1:-1].values + train1.iloc[-24*7*3-24*(8-i)*1:-24*7*3-24*(7-i),1:-1].values)/4)\\\n",
    "                 * 0.4 + sub.iloc[24*(i-2)*1:24*(i-1),1:].values * 0.6\n",
    "        sub.iloc[24*(i-1)*1:24*(i),1:] = sub1\n",
    "\n",
    "sub2 = ((train2.iloc[-24*7*1:-24*6,1:-1].values + train2.iloc[-24*7*2:-24*7*1-24*6,1:-1].values + \\\n",
    "         train2.iloc[-24*7*3:-24*7*2-24*6,1:-1].values)/3)\\\n",
    "             * 0.2 + train2.iloc[-24*1:,1:-1].values * 0.8\n",
    "sub.loc[(sub['time']>='2022-06-01 01:00:00')&(sub['time']<'2022-06-02 01:00:00'),1:] = sub2\n",
    "for i in range(2, 8):\n",
    "    if i == 7 :\n",
    "        sub.iloc[24*7*1 + 24*(i-1)*1:24*7 + 24*(i),1:] = ((train2.iloc[-24*1:,1:-1].values + train2.iloc[-24*7*1-24*1:-24*7*1,1:-1].values +\\\n",
    "            + train2.iloc[-24*7*2-24*1:-24*7*2,1:-1].values)/3)\\\n",
    "                 * 0.4 + sub.iloc[24*7*1 + 24*(i-2)*1:24*7*1 + 24*(i-1),1:].values * 0.6\n",
    "    else:\n",
    "        sub.iloc[24*7*1 + 24*(i-1)*1:24*7*1 + 24*(i),1:] = ((train2.iloc[-24*(8-i)*1:-24*(7-i),1:-1].values + train2.iloc[-24*7*1-24*(8-i)*1:-24*7*1-24*(7-i),1:-1].values +\\\n",
    "            train2.iloc[-24*7*2-24*(8-i)*1:-24*7*2-24*(7-i),1:-1].values)/3)\\\n",
    "                 *0.4 + sub.iloc[24*7*1 + 24*(i-2)*1:24*7*1 + 24*(i-1),1:].values * 0.6\n",
    "        \n",
    "sub3 = ((train3.iloc[-24*7*1:-24*6,1:-1].values + train3.iloc[-24*7*2:-24*7*1-24*6,1:-1].values + \\\n",
    "         train3.iloc[-24*7*3:-24*7*2-24*6,1:-1].values + train3.iloc[-24*7*4:-24*7*3-24*6,1:-1].values)/4)\\\n",
    "             * 0.2 + train3.iloc[-24*1:,1:-1].values * 0.8\n",
    "sub.loc[(sub['time']>='2022-07-21 01:00:00')&(sub['time']<'2022-07-22 01:00:00'),1:] = sub3\n",
    "for i in range(2, 8):\n",
    "    if i == 7 :\n",
    "        sub.iloc[24*7*2 + 24*(i-1)*1:24*7*2 + 24*(i),1:] = ((train3.iloc[-24*1:,1:-1].values + train3.iloc[-24*7*1-24*1:-24*7*1,1:-1].values +\\\n",
    "            + train3.iloc[-24*7*2-24*1:-24*7*2,1:-1].values + train3.iloc[-24*7*3-24*1:-24*7*3,1:-1].values)/4)\\\n",
    "                 * 0.4 + sub.iloc[24*7*2 + 24*(i-2)*1:24*7*2 + 24*(i-1),1:].values * 0.6\n",
    "    else:\n",
    "        sub.iloc[24*7*2 + 24*(i-1)*1:24*7*2 + 24*(i),1:] = ((train3.iloc[-24*(8-i)*1:-24*(7-i),1:-1].values + train3.iloc[-24*7*1-24*(8-i)*1:-24*7*1-24*(7-i),1:-1].values +\\\n",
    "            train3.iloc[-24*7*2-24*(8-i)*1:-24*7*2-24*(7-i),1:-1].values + train3.iloc[-24*7*3-24*(8-i)*1:-24*7*3-24*(7-i),1:-1].values)/4)\\\n",
    "                 * 0.4 + sub.iloc[24*7*2 + 24*(i-2)*1:24*7*2 + 24*(i-1),1:].values * 0.6\n",
    "\n",
    "sub4 = ((train4.iloc[-24*7*1:-24*6,1:-1].values + train4.iloc[-24*7*2:-24*7*1-24*6,1:-1].values + \\\n",
    "         train4.iloc[-24*7*3:-24*7*2-24*6,1:-1].values)/3)\\\n",
    "             * 0.2 + train4.iloc[-24*1:,1:-1].values * 0.8\n",
    "sub.loc[(sub['time']>='2022-08-21 01:00:00')&(sub['time']<'2022-08-22 01:00:00'),1:] = sub4\n",
    "for i in range(2, 8):\n",
    "    if i == 7 :\n",
    "        sub.iloc[24*7*3 + 24*(i-1)*1:24*7*3 + 24*(i),1:] = ((train4.iloc[-24*1:,1:-1].values + train4.iloc[-24*7*1-24*1:-24*7*1,1:-1].values +\\\n",
    "            + train4.iloc[-24*7*2-24*1:-24*7*2,1:-1].values)/3) \\\n",
    "                * 0.4 + sub.iloc[24*7*3 + 24*(i-2)*1:24*7*3 + 24*(i-1),1:].values * 0.6\n",
    "    else:\n",
    "        sub.iloc[24*7*3 + 24*(i-1)*1:24*7*3 + 24*(i),1:] = ((train4.iloc[-24*(8-i)*1:-24*(7-i),1:-1].values + train4.iloc[-24*7*1-24*(8-i)*1:-24*7*1-24*(7-i),1:-1].values +\\\n",
    "            train4.iloc[-24*7*2-24*(8-i)*1:-24*7*2-24*(7-i),1:-1].values)/3)\\\n",
    "                 * 0.4 + sub.iloc[24*7*3 + 24*(i-2)*1:24*7*3 + 24*(i-1),1:].values * 0.6\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9783945404427217"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "test = pd.read_csv('use_4week_mean.csv').iloc[:,1:].values\n",
    "pred = sub.iloc[:,1:].values\n",
    "\n",
    "msle = tf.keras.losses.MeanSquaredLogarithmicError()\n",
    "\n",
    "1/(1+msle(test, pred).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('test.csv',index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4591a7979a1891d2646866206506d42720cfeca63f9104a6d414ca12b5b922af"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
